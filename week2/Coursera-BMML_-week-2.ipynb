{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation-maximization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will derive and implement formulas for Gaussian Mixture Model â€” one of the most commonly used methods for performing soft clustering of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "We will need ```numpy```, ```scikit-learn```, ```matplotlib``` libraries for this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching package metadata ...........\n",
      "Solving package specifications: .\n",
      "\n",
      "Package plan for installation in environment /Users/adamcox/miniconda2/envs/bayescourse:\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    asn1crypto:   0.24.0-py36_0        \n",
      "    cffi:         1.11.5-py36h342bebf_0\n",
      "    chardet:      3.0.4-py36h96c241c_1 \n",
      "    cryptography: 2.2.2-py36h1de35cc_0 \n",
      "    idna:         2.6-py36h8628d0a_1   \n",
      "    pycparser:    2.18-py36h724b2fc_1  \n",
      "    pyopenssl:    17.5.0-py36h51e4350_0\n",
      "    pysocks:      1.6.8-py36_0         \n",
      "    requests:     2.18.4-py36h4516966_1\n",
      "    urllib3:      1.22-py36h68b9469_0  \n",
      "\n",
      "cryptography-2 100% |################################| Time: 0:00:00   2.32 MB/s\n"
     ]
    }
   ],
   "source": [
    "!conda install -y requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import slogdet, det, solve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from sklearn.datasets import load_digits\n",
    "from grader import Grader\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading\n",
    "We will create a grader instance below and use it to collect your answers. Note that these outputs will be stored locally inside grader and will be uploaded to the platform only after running submitting function in the last part of this assignment. If you want to make a partial submission, you can run that cell anytime you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader = Grader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing EM for GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For debugging we will use samples from gaussian mixture model with unknown mean, variance and priors. We also added inital values of parameters for grading purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = np.load('samples.npz')\n",
    "X = samples['data']\n",
    "pi0 = samples['pi0']\n",
    "mu0 = samples['mu0']\n",
    "sigma0 = samples['sigma0']\n",
    "plt.scatter(X[:, 0], X[:, 1], c='grey', s=30)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.90096725, 1.11952236],\n",
       "       [1.11952236, 6.19660175]])"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = X[np.random.randint(0,X.shape[0],size=int(X.shape[0]/3)),:]\n",
    "print(xx.shape)\n",
    "np.cov(xx.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mu0', 'pi0', 'data', 'sigma0']"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 2)"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3451814 , 0.6066179 , 0.04820071])"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.00490413,  1.89980228],\n",
       "        [ 1.89980228,  4.18354574]],\n",
       "\n",
       "       [[ 1.96867815,  0.78415336],\n",
       "        [ 0.78415336,  1.83319942]],\n",
       "\n",
       "       [[ 0.19316335, -0.11648642],\n",
       "        [-0.11648642,  1.98395967]]])"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, that EM algorithm is a coordinate descent optimization of variational lower bound $\\mathcal{L}(\\theta, q) = \\int q(T) \\log\\frac{P(X, T|\\theta)}{q(T)}dT\\to \\max$.\n",
    "\n",
    "<b>E-step</b>:<br>\n",
    "$\\mathcal{L}(\\theta, q) \\to \\max\\limits_{q} \\Leftrightarrow \\mathcal{KL} [q(T) \\,\\|\\, p(T|X, \\theta)] \\to \\min \\limits_{q\\in Q} \\Rightarrow q(T) = p(T|X, \\theta)$<br>\n",
    "<b>M-step</b>:<br> \n",
    "$\\mathcal{L}(\\theta, q) \\to \\max\\limits_{\\theta} \\Leftrightarrow \\mathbb{E}_{q(T)}\\log p(X,T | \\theta) \\to \\max\\limits_{\\theta}$\n",
    "\n",
    "For GMM, $\\theta$ is a set of parameters that consists of mean vectors $\\mu_c$, covariance matrices $\\Sigma_c$ and priors $\\pi_c$ for each component.\n",
    "\n",
    "Latent variables $T$ are indices of components to which each data point is assigned. $T_i$ (cluster index for object $i$) is a binary vector with only one active bit in position corresponding to the true component. For example, if we have $C=3$ components and object $i$ lies in first component, $T_i = [1, 0, 0]$.\n",
    "\n",
    "The joint distribution can be written as follows: $p(T, X \\mid \\theta) =  \\prod\\limits_{i=1}^N p(T_i, X_i \\mid \\theta) = \\prod\\limits_{i=1}^N \\prod\\limits_{c=1}^C [\\pi_c \\mathcal{N}(X_i \\mid \\mu_c, \\Sigma_c)]^{T_{ic}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E-step\n",
    "In this step we need to estimate the posterior distribution over the latent variables with fixed values of parameters: $q(T) = p(T|X, \\theta)$. We will assume that $T_i$ (cluster index for object $i$) is a binary vector with only one '1' in position corresponding to the true component. To do so we need to compute $\\gamma_{ic} = P(T_{ic} = 1 \\mid X, \\theta)$. Note that $\\sum\\limits_{c=1}^C\\gamma_{ic}=1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Important trick 1:</b> It is important to avoid numerical errors. At some point you will have to compute the formula of the following form: $\\frac{e^{x_i}}{\\sum_j e^{x_j}}$. When you compute exponents of large numbers, you get huge numerical errors (some numbers will simply become infinity). You can avoid this by dividing numerator and denominator by $e^{\\max(x)}$: $\\frac{e^{x_i-\\max(x)}}{\\sum_j e^{x_j - \\max(x)}}$. After this transformation maximum value in the denominator will be equal to one. All other terms will contribute smaller values. This trick is called log-sum-exp. So, to compute desired formula you first subtract maximum value from each component in vector $X$ and then compute everything else as before.\n",
    "\n",
    "<b>Important trick 2:</b> You will probably need to compute formula of the form $A^{-1}x$ at some point. You would normally inverse $A$ and then multiply it by $x$. A bit faster and more numerically accurate way to do this is to solve the equation $Ay = x$. Its solution is $y=A^{-1}x$, but the equation $Ay = x$ can be solved by Gaussian elimination procedure. You can use ```np.linalg.solve``` for this.\n",
    "\n",
    "<b>Other usefull functions: </b> <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.slogdet.html\">```slogdet```</a> and <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.det.html#numpy.linalg.det\">```det```</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task 1:</b> Implement E-step for GMM using template below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "\n",
    "def my_multivariate_normal(x, mean, cov):\n",
    "    # only works for x = a 1d array\n",
    "    xx = x - mean\n",
    "    d = x.shape[-1]\n",
    "    return ((2*np.pi)**-d/2.) * (det(cov)**-0.5) * np.exp(-0.5*( np.dot(xx.T, np.linalg.solve(cov, xx)))) \n",
    "\n",
    "def E_step(X, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Performs E-step on GMM model\n",
    "    Each input is numpy array:\n",
    "    X: (N x d), data points\n",
    "    pi: (C), mixture component weights \n",
    "    mu: (C x d), mixture component means\n",
    "    sigma: (C x d x d), mixture component covariance matrices\n",
    "    \n",
    "    Returns:\n",
    "    gamma: (N x C), probabilities of clusters for objects\n",
    "    \"\"\"\n",
    "    N = X.shape[0] # number of objects\n",
    "    C = pi.shape[0] # number of clusters\n",
    "    d = mu.shape[1] # dimension of each object\n",
    "    gamma = np.zeros((N, C)) # distribution q(T)\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    #there's certainly a way to do this without for-loops\n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            #xrow = X[n,:] - np.max(X[n,:])\n",
    "            xrow = X[n,:]\n",
    "            #print(xrow)\n",
    "            #print(np.max(xrow))\n",
    "            #print(xrow - np.max(xrow))\n",
    "            #xrow = xrow[np.newaxis,:]\n",
    "            #print(xrow.shape)\n",
    "            #print(sigma[c,:,:].shape)\n",
    "            #gamma[n,c] = pi[c]* my_multivariate_normal(xrow, mu[c], sigma[c,:,:])\n",
    "            gamma[n,c] = pi[c]*multivariate_normal.pdf(xrow, mean = mu[c], cov=sigma[c,:,:])\n",
    "    \n",
    "       \n",
    "    #now need to normalize gamma[n,c]\n",
    "    gamma = gamma / np.sum(gamma, axis=1)[:, np.newaxis]  #this [:, np.newaxis] term \n",
    "        \n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 280)"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = X - mu[0]\n",
    "np.linalg.solve(sigma0[0,:,:], xx.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.66251522, 0.4966314 ],\n",
       "       [0.4966314 , 6.04389122]])"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfx = my_multivariate_normal(X[10,:], mu[0], sigma[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010631487828468204"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task Task 1 (E-step) is: 0.5337178741081263\n"
     ]
    }
   ],
   "source": [
    "gamma = E_step(X, pi0, mu0, sigma0)\n",
    "grader.submit_e_step(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280.0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 23.46798135, 241.38191992,  15.15009873])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M-step\n",
    "\n",
    "In M-step we need to maximize $\\mathbb{E}_{q(T)}\\log p(X,T | \\theta)$ with respect to $\\theta$. In our model this means that we need to find optimal values of $\\pi$, $\\mu$, $\\Sigma$. To do so, you need to compute the derivatives and \n",
    "set them to zero. You should start by deriving formulas for $\\mu$ as it is the easiest part. Then move on to $\\Sigma$. Here it is crucial to optimize function w.r.t. to $\\Lambda = \\Sigma^{-1}$ and then inverse obtained result. Finaly, to compute $\\pi$, you will need <a href=\"https://www3.nd.edu/~jstiver/FIN360/Constrained%20Optimization.pdf\">Lagrange Multipliers technique</a> to satisfy constraint $\\sum\\limits_{i=1}^{n}\\pi_i = 1$.\n",
    "\n",
    "<br>\n",
    "<b>Important note:</b> You will need to compute derivatives of scalars with respect to matrices. To refresh this technique from previous courses, see <a href=\"https://en.wikipedia.org/wiki/Matrix_calculus\"> wiki article</a> about it . Main formulas of matrix derivatives can be found in <a href=\"http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/3274/pdf/imm3274.pdf\">Chapter 2 of The Matrix Cookbook</a>. For example, there you may find that $\\frac{\\partial}{\\partial A}\\log |A| = A^{-T}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task 2:</b> Implement M-step for GMM using template below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.dot(gamma.T, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  50.68968134,   33.19292417],\n",
       "       [ 360.35846131, 1065.32652211],\n",
       "       [  54.94639267,   26.33300995]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 23.46798135],\n",
       "       [241.38191992],\n",
       "       [ 15.15009873]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.sum(axis=0).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  50.68968134   33.19292417]\n",
      " [ 360.35846131 1065.32652211]\n",
      " [  54.94639267   26.33300995]]\n",
      "[[ 23.46798135]\n",
      " [241.38191992]\n",
      " [ 15.15009873]]\n",
      "[[2.15995064 1.41439196]\n",
      " [1.49289749 4.41344788]\n",
      " [3.62680096 1.73814114]]\n"
     ]
    }
   ],
   "source": [
    "mu = np.dot(gamma.T, X)\n",
    "print(mu)\n",
    "print(gamma.sum(axis=0)[:,np.newaxis])\n",
    "mu = np.divide(mu,gamma.sum(axis=0).reshape(-1,1))\n",
    "print(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = X - mu[0]\n",
    "np.dot(diff.T, diff).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [2. 3.]\n",
      " [4. 5.]]\n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 2.,  3.],\n",
       "       [ 8., 10.]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.arange(6.0).reshape((3, 2))\n",
    "x2 = np.arange(3.0).reshape((3,1))\n",
    "\n",
    "print(x1)\n",
    "print(x2)\n",
    "np.multiply(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.17228095e+00,  5.75213236e+00],\n",
       "       [ 1.05443001e+00,  5.10029341e+00],\n",
       "       [ 1.21814807e+00,  5.15920217e+00],\n",
       "       [ 1.75362297e+00,  7.88315382e+00],\n",
       "       [ 2.05005447e+00,  7.38909041e+00],\n",
       "       [ 2.20779501e+00,  3.44969157e+00],\n",
       "       [ 5.29273819e+00,  3.15319415e+00],\n",
       "       [ 3.79661006e-02,  6.00430278e+00],\n",
       "       [ 7.17431136e-01,  6.13701974e+00],\n",
       "       [-1.18307081e+00,  1.58755199e+00],\n",
       "       [-8.17944961e-01,  2.63902188e+00],\n",
       "       [ 1.21663018e+00,  5.58031550e+00],\n",
       "       [-2.54147644e-01,  1.10080559e+00],\n",
       "       [ 3.02128295e+00,  6.09120151e+00],\n",
       "       [ 2.48589386e+00,  4.31904544e+00],\n",
       "       [ 6.06880749e-02,  3.54822919e+00],\n",
       "       [ 1.37942797e+00, -1.69794694e-01],\n",
       "       [ 1.53537865e+00,  7.41921097e+00],\n",
       "       [-2.07335270e-01,  1.30016067e+00],\n",
       "       [ 3.14906787e+00,  5.85690104e+00],\n",
       "       [ 2.44103605e-01,  4.66387340e+00],\n",
       "       [ 5.36539238e+00,  3.95180149e+00],\n",
       "       [ 7.30859440e-01,  7.00801146e+00],\n",
       "       [ 1.80023535e-01,  5.88478502e+00],\n",
       "       [ 1.53047798e+00,  4.05999791e+00],\n",
       "       [ 7.91333617e-01,  5.71722906e+00],\n",
       "       [ 6.55654575e-02,  9.05426617e-01],\n",
       "       [ 1.38467398e+00,  6.63742426e+00],\n",
       "       [ 1.79979815e+00,  6.71734412e+00],\n",
       "       [ 8.28621197e-01,  3.04987927e+00],\n",
       "       [ 1.75036044e+00,  4.24738427e+00],\n",
       "       [ 2.15780196e+00,  1.47856230e+00],\n",
       "       [ 8.28676961e-01,  6.28380383e-01],\n",
       "       [ 2.16434984e-01,  9.26169832e-01],\n",
       "       [ 5.50128803e-01,  5.37697581e+00],\n",
       "       [ 2.38266864e+00,  5.18139984e+00],\n",
       "       [ 9.21053412e-01,  5.70318952e+00],\n",
       "       [ 1.46824563e+00,  7.89259375e+00],\n",
       "       [ 1.80404389e+00,  5.52711683e+00],\n",
       "       [-1.35372844e-01,  2.21808015e+00],\n",
       "       [ 4.62866329e+00,  2.91729119e+00],\n",
       "       [ 3.85513598e+00, -4.37458909e-01],\n",
       "       [ 1.25478561e+00,  1.02320796e+00],\n",
       "       [ 1.43044841e+00,  5.63900429e+00],\n",
       "       [ 2.57838322e+00,  1.88864546e+00],\n",
       "       [-7.12000233e-01,  6.04217446e+00],\n",
       "       [ 9.50127959e-01, -9.34405235e-01],\n",
       "       [ 8.59612915e-01,  4.16013961e+00],\n",
       "       [ 1.33340031e+00,  4.46900078e+00],\n",
       "       [ 2.28097313e-03,  6.18740059e+00],\n",
       "       [-1.27745831e-01,  2.67346919e+00],\n",
       "       [ 1.05177972e+00,  7.88870301e-01],\n",
       "       [ 2.98444207e-01, -7.41814209e-01],\n",
       "       [ 7.44859547e+00,  5.10469501e+00],\n",
       "       [ 1.96411615e+00,  6.07498364e+00],\n",
       "       [ 6.55587129e-01,  1.01841964e-01],\n",
       "       [ 6.06282290e+00,  4.19903133e+00],\n",
       "       [ 1.90795092e+00,  5.03222045e+00],\n",
       "       [-1.33650845e-01,  1.69295177e+00],\n",
       "       [ 1.67282854e+00,  3.00733371e+00],\n",
       "       [ 8.41193517e-01,  2.89067493e-01],\n",
       "       [ 1.04471735e+00,  6.17667453e+00],\n",
       "       [-1.54504350e+00,  5.65613984e-01],\n",
       "       [-1.13853798e-01,  4.49026398e+00],\n",
       "       [ 1.91868384e+00,  7.28362874e+00],\n",
       "       [ 1.00779443e+00,  7.14828357e+00],\n",
       "       [ 4.31762587e-01,  2.65185979e+00],\n",
       "       [ 3.84805094e+00,  2.86355455e+00],\n",
       "       [-3.35238782e-01, -2.90631904e-02],\n",
       "       [ 3.80401143e-01,  7.06808394e+00],\n",
       "       [ 1.82417608e+00,  5.04868577e+00],\n",
       "       [ 2.24337126e-01,  5.92130256e+00],\n",
       "       [ 6.59334736e-01,  7.29999028e+00],\n",
       "       [ 7.34370047e+00,  5.05385313e+00],\n",
       "       [ 9.91611285e-01, -1.55261353e-01],\n",
       "       [ 5.09749823e+00,  2.88102600e+00],\n",
       "       [ 3.18859049e-01,  2.72265595e+00],\n",
       "       [ 1.21866814e+00,  6.21258467e+00],\n",
       "       [ 2.24323003e+00,  5.35313608e+00],\n",
       "       [-2.06916261e-01,  2.50511640e-02],\n",
       "       [ 1.70688539e+00,  5.34792446e+00],\n",
       "       [ 2.80925852e+00,  7.47969546e+00],\n",
       "       [ 1.39928975e+00,  6.30461599e-01],\n",
       "       [ 9.28624137e-01,  6.61272881e+00],\n",
       "       [ 1.63769046e+00,  2.02376264e+00],\n",
       "       [ 1.15164121e-01,  1.23235414e+00],\n",
       "       [ 1.99122691e+00,  5.74855367e+00],\n",
       "       [ 5.49601619e+00,  3.50792900e+00],\n",
       "       [ 1.64027822e+00,  5.11820300e+00],\n",
       "       [ 3.47025332e+00, -3.13939623e-02],\n",
       "       [ 1.38024349e+00,  5.32545816e+00],\n",
       "       [ 1.07609829e+00, -1.14385512e+00],\n",
       "       [ 3.71602779e+00, -1.24885308e+00],\n",
       "       [ 2.22826831e+00, -1.51667641e-01],\n",
       "       [ 4.55204110e+00,  3.95085815e+00],\n",
       "       [-9.48514713e-01,  5.11682395e+00],\n",
       "       [ 4.09485658e-01,  4.65397035e+00],\n",
       "       [ 1.38047573e+00,  5.70108587e-01],\n",
       "       [ 3.13782847e+00,  7.53836201e-01],\n",
       "       [ 5.81913064e+00,  3.99649479e+00],\n",
       "       [ 4.52859227e-01,  6.41737533e+00],\n",
       "       [ 1.42731546e+00,  6.02591123e+00],\n",
       "       [ 1.04158269e+00,  3.87923359e-01],\n",
       "       [ 1.73779650e+00,  7.19658247e-01],\n",
       "       [ 2.42582556e+00,  4.77945288e+00],\n",
       "       [ 1.09592795e+00,  5.06008719e+00],\n",
       "       [-1.45614922e+00,  5.95579921e+00],\n",
       "       [ 6.72249455e+00,  4.87447705e+00],\n",
       "       [ 2.17122860e+00,  1.51377507e+00],\n",
       "       [-1.10761991e-01,  4.69226154e+00],\n",
       "       [ 2.29496783e+00,  5.42072124e+00],\n",
       "       [ 1.14295165e+00,  1.30171920e-01],\n",
       "       [ 6.17089978e-01,  2.83817535e+00],\n",
       "       [ 1.22692117e+00,  7.84765306e-01],\n",
       "       [ 4.73360667e-01,  7.70186389e-01],\n",
       "       [ 6.53358247e-01,  4.93344148e+00],\n",
       "       [ 1.40046157e-02,  1.59633268e+00],\n",
       "       [ 1.40830824e+00,  4.91199064e+00],\n",
       "       [ 8.54232030e-02,  4.98565677e+00],\n",
       "       [ 6.95346826e+00,  5.04251028e+00],\n",
       "       [ 1.28854841e+00,  5.72271773e+00],\n",
       "       [ 2.44205882e+00,  6.55981677e+00],\n",
       "       [ 1.47439722e+00,  6.92281604e+00],\n",
       "       [ 1.50968857e+00,  4.23383548e-01],\n",
       "       [ 7.08911152e-01,  1.92696259e+00],\n",
       "       [ 6.74351097e+00,  5.59327053e+00],\n",
       "       [ 1.19888314e+00, -1.76991308e+00],\n",
       "       [ 4.63591705e-01,  5.87675592e+00],\n",
       "       [-1.11404336e+00,  9.46390557e-01],\n",
       "       [ 7.80532323e+00,  6.10231470e+00],\n",
       "       [ 1.82434739e+00,  5.40757741e+00],\n",
       "       [ 2.19961789e+00, -8.21169734e-01],\n",
       "       [-7.31324079e-01,  5.29271949e+00],\n",
       "       [ 2.19095517e+00, -1.85434167e-01],\n",
       "       [ 1.13871010e+00,  5.96400884e+00],\n",
       "       [-1.25074517e+00, -3.50542031e-01],\n",
       "       [ 2.85604676e+00,  1.92717505e+00],\n",
       "       [ 7.67649609e+00,  5.69599157e+00],\n",
       "       [ 2.90662901e+00,  1.24694079e+00],\n",
       "       [ 1.21320993e+00,  7.64086825e+00],\n",
       "       [ 1.87514302e+00,  5.76554685e+00],\n",
       "       [ 2.63023051e+00,  5.55409537e+00],\n",
       "       [ 1.41789035e+00,  6.90863452e+00],\n",
       "       [ 8.17272288e+00,  5.55090148e+00],\n",
       "       [ 1.02611693e+00, -1.49201446e-01],\n",
       "       [ 1.76826842e+00,  7.84372079e+00],\n",
       "       [ 1.27288235e+00,  7.58000235e+00],\n",
       "       [ 1.34939917e-01,  5.23554109e+00],\n",
       "       [ 1.74347283e+00,  5.40938363e+00],\n",
       "       [ 1.14531814e+00,  6.92145026e+00],\n",
       "       [ 3.58359732e+00,  2.62881378e+00],\n",
       "       [ 3.33428328e+00,  5.90988496e+00],\n",
       "       [ 1.26750995e+00,  6.20589213e+00],\n",
       "       [ 2.01185673e+00,  6.75314375e+00],\n",
       "       [ 9.16583082e-01,  5.81346837e+00],\n",
       "       [ 5.59727960e-01,  2.14385338e+00],\n",
       "       [ 3.20066085e+00,  6.27051570e+00],\n",
       "       [ 1.77198207e+00,  6.79430850e-01],\n",
       "       [ 2.15418928e+00,  4.90484753e+00],\n",
       "       [ 1.28963297e+00,  6.33025968e+00],\n",
       "       [ 6.73906082e+00,  5.03065169e+00],\n",
       "       [ 2.48259720e+00,  8.78121198e-01],\n",
       "       [ 9.99053803e-01,  1.48924870e-02],\n",
       "       [ 5.75650891e-01,  4.15503001e-01],\n",
       "       [ 1.24184549e+00,  1.43678326e-01],\n",
       "       [ 5.82957408e+00,  3.88783976e+00],\n",
       "       [ 6.56295773e-01,  7.45855398e+00],\n",
       "       [ 2.37296740e+00,  4.71993070e+00],\n",
       "       [-1.48963454e-01,  5.10833719e+00],\n",
       "       [ 2.30799608e+00,  1.23493727e+00],\n",
       "       [ 1.84553500e+00,  2.32539884e+00],\n",
       "       [ 5.98783970e+00,  3.79101920e+00],\n",
       "       [ 5.68719089e+00,  3.54180936e+00],\n",
       "       [ 1.90446650e+00,  1.24711991e+00],\n",
       "       [ 2.45931192e-02,  6.40724494e+00],\n",
       "       [ 1.84223120e+00, -1.59672037e+00],\n",
       "       [-1.52666689e-01,  6.15135192e+00],\n",
       "       [-5.35412073e-01,  6.21941055e+00],\n",
       "       [ 3.87094645e-01,  7.41660967e+00],\n",
       "       [-6.14883362e-01,  3.60615726e+00],\n",
       "       [ 1.30463003e+00,  7.68305438e+00],\n",
       "       [ 3.44683044e+00,  6.54630399e+00],\n",
       "       [ 7.24093815e-01,  4.10978217e+00],\n",
       "       [ 6.37523048e+00,  4.31647627e+00],\n",
       "       [ 6.81785190e-01,  7.48517604e+00],\n",
       "       [ 5.84166428e-01,  5.48862565e+00],\n",
       "       [ 2.21035655e-01,  5.07928162e+00],\n",
       "       [ 1.03487457e+00,  8.00486382e+00],\n",
       "       [ 6.70312342e-02,  2.30779324e+00],\n",
       "       [ 1.45058312e-01,  6.08623810e+00],\n",
       "       [ 3.51563949e+00,  5.90551541e+00],\n",
       "       [-1.21743069e+00,  2.01812486e+00],\n",
       "       [ 1.25534130e+00,  6.52236919e+00],\n",
       "       [ 1.52651115e+00,  2.74422557e+00],\n",
       "       [ 4.17820953e-01,  4.14281229e+00],\n",
       "       [ 7.83819163e-01,  7.22435624e+00],\n",
       "       [ 1.52608873e+00, -1.04848514e+00],\n",
       "       [ 2.62190103e+00,  4.08989819e+00],\n",
       "       [ 1.52141180e+00,  5.44636807e+00],\n",
       "       [ 1.27089960e+00,  5.83315410e+00],\n",
       "       [-1.15830820e+00,  6.57875861e+00],\n",
       "       [ 9.08096659e-01,  2.43601515e-01],\n",
       "       [-1.22799101e+00,  9.15552871e-02],\n",
       "       [ 7.60712169e-01,  4.72431851e+00],\n",
       "       [ 8.89125535e-01,  5.49148457e+00],\n",
       "       [ 7.19277453e+00,  5.37362018e+00],\n",
       "       [ 7.19969516e-01,  6.43598975e+00],\n",
       "       [ 2.07924181e+00,  6.00321138e-01],\n",
       "       [ 5.61934865e+00,  3.66621824e+00],\n",
       "       [ 5.81465174e-01,  6.05009709e+00],\n",
       "       [ 2.91693856e+00,  7.10829708e+00],\n",
       "       [ 1.75268533e+00,  1.86358473e-02],\n",
       "       [ 1.63434671e+00,  6.32185452e+00],\n",
       "       [ 8.09428576e+00,  5.08941822e+00],\n",
       "       [ 4.97104996e-01,  6.44127704e+00],\n",
       "       [ 7.30307355e-01,  2.03845021e+00],\n",
       "       [ 1.88012881e+00,  5.93895011e+00],\n",
       "       [ 3.17900554e+00, -2.09545453e-01],\n",
       "       [ 1.58528165e+00,  4.28470740e+00],\n",
       "       [ 1.86390248e+00,  6.85825822e+00],\n",
       "       [ 1.52057080e+00,  3.43286292e+00],\n",
       "       [ 2.91819526e+00,  5.72908139e+00],\n",
       "       [-2.99319130e-01,  5.42789197e+00],\n",
       "       [ 1.41194500e+00,  7.35910175e+00],\n",
       "       [ 2.95511537e+00,  6.01819397e+00],\n",
       "       [ 1.66991534e-01,  5.83623411e+00],\n",
       "       [ 5.19364819e-02,  5.65715895e+00],\n",
       "       [ 1.75519224e+00,  1.90483339e+00],\n",
       "       [ 1.35321852e+00,  5.69950925e+00],\n",
       "       [-1.91479924e-01,  6.43436677e+00],\n",
       "       [ 1.22101770e+00,  6.79450662e-02],\n",
       "       [ 1.78380398e+00,  6.30847344e+00],\n",
       "       [-3.55110244e-02,  1.82042904e+00],\n",
       "       [ 2.20118446e+00,  3.30215176e+00],\n",
       "       [ 1.04406025e+00,  5.74603461e+00],\n",
       "       [ 2.40516077e+00,  6.77959745e+00],\n",
       "       [ 2.54717242e-01,  2.16332784e-02],\n",
       "       [ 7.97021306e-01,  2.09803561e+00],\n",
       "       [ 7.37141542e-01,  1.84090527e+00],\n",
       "       [ 5.67847626e+00,  3.11218785e+00],\n",
       "       [ 1.29797955e+00,  7.14449431e-01],\n",
       "       [ 4.47203781e-01,  6.90901980e+00],\n",
       "       [ 2.53547232e+00,  2.22812918e-01],\n",
       "       [ 4.71032780e-02,  2.70833703e+00],\n",
       "       [ 1.05170708e+00,  6.24245870e+00],\n",
       "       [ 1.22719793e+00,  5.31044887e+00],\n",
       "       [ 9.05682707e-01,  3.97080835e+00],\n",
       "       [ 4.65742415e-01,  4.09360330e-01],\n",
       "       [ 1.06076701e+00,  4.90565946e+00],\n",
       "       [ 1.62230178e+00,  4.75497328e+00],\n",
       "       [-6.75943219e-01,  1.01942991e+00],\n",
       "       [ 1.60403460e+00,  5.23971318e+00],\n",
       "       [ 2.65552208e+00,  6.28439369e+00],\n",
       "       [-8.79363302e-01,  2.68361961e+00],\n",
       "       [ 1.35809511e+00,  6.18625348e+00],\n",
       "       [ 8.06669542e+00,  6.53431901e+00],\n",
       "       [ 6.28853785e-01,  6.05463295e-01],\n",
       "       [ 1.20521706e+00,  4.38770832e+00],\n",
       "       [ 1.51483282e+00,  4.94236568e+00],\n",
       "       [ 2.79508851e+00,  6.29377004e+00],\n",
       "       [ 2.11392387e+00,  3.78071934e+00],\n",
       "       [-1.04920085e+00, -2.86354706e-01],\n",
       "       [ 1.92995511e+00,  5.87823616e+00],\n",
       "       [ 6.48021223e-01,  1.92290319e+00],\n",
       "       [ 1.41531713e+00,  5.61488036e+00],\n",
       "       [-1.71354162e+00,  4.35964878e+00],\n",
       "       [ 1.57195184e+00,  5.28963241e+00],\n",
       "       [ 2.24183315e+00,  5.90291853e-01],\n",
       "       [ 6.83398279e+00,  5.33623657e+00],\n",
       "       [ 1.22742337e+00,  6.66310138e+00],\n",
       "       [ 6.74958659e-01,  8.08548733e+00],\n",
       "       [ 1.51781594e+00,  7.32020269e+00],\n",
       "       [-1.50692688e+00,  2.07662159e+00],\n",
       "       [ 1.01552968e+00,  1.51154386e+00],\n",
       "       [ 1.11941319e+00,  4.97081518e+00],\n",
       "       [ 8.62533136e+00,  6.66402501e+00],\n",
       "       [-9.47690561e-01,  1.07572041e+00],\n",
       "       [ 2.29142304e+00,  6.98402001e+00],\n",
       "       [ 6.43998438e-01,  5.83529671e+00],\n",
       "       [-1.35169889e-01,  4.57055492e+00]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.98540731, 0.70012896, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.99364669, 1.        , 0.99989698,\n",
       "       1.        , 0.61126479, 1.        , 0.99811911, 0.99999999,\n",
       "       1.        , 0.58339716, 1.        , 1.        , 0.99999994,\n",
       "       1.        , 0.85114896, 1.        , 1.        , 0.99999801,\n",
       "       0.99999991, 0.44652749, 0.40367352, 0.75664228, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.99999954,\n",
       "       0.6421527 , 0.56043234, 0.40505999, 1.        , 0.44796917,\n",
       "       1.        , 0.67038353, 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.40664949, 0.50665808, 0.71294586, 1.        ,\n",
       "       0.4309033 , 0.66731561, 1.        , 0.99989037, 0.99258051,\n",
       "       0.43072152, 1.        , 0.99999353, 1.        , 1.        ,\n",
       "       1.        , 0.99999799, 0.49610888, 0.47040807, 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.71048733, 0.5277669 ,\n",
       "       0.7060901 , 0.99999974, 1.        , 1.        , 0.43993049,\n",
       "       1.        , 1.        , 0.45947262, 1.        , 0.51287509,\n",
       "       0.96632316, 1.        , 0.68428367, 1.        , 0.65806754,\n",
       "       1.        , 0.70632688, 0.45586611, 0.71422896, 0.43645534,\n",
       "       1.        , 1.        , 0.46595414, 0.71435596, 0.66096254,\n",
       "       1.        , 1.        , 0.44310023, 0.50242807, 0.99999954,\n",
       "       1.        , 1.        , 0.66492178, 0.44360086, 1.        ,\n",
       "       1.        , 0.50141212, 0.99999801, 0.41958651, 0.46608872,\n",
       "       1.        , 0.99900099, 1.        , 1.        , 0.67415788,\n",
       "       1.        , 1.        , 1.        , 0.51563862, 0.98275784,\n",
       "       0.52845046, 0.70252014, 1.        , 0.99998911, 0.64065078,\n",
       "       1.        , 0.69922943, 1.        , 0.71411505, 1.        ,\n",
       "       0.88684232, 0.48598761, 0.68334835, 0.63269601, 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.7161194 , 0.5335671 ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.49064961, 0.99999997, 1.        , 1.        , 1.        ,\n",
       "       0.99901632, 1.        , 0.51687378, 1.        , 1.        ,\n",
       "       0.64162192, 0.62216952, 0.49604666, 0.40218789, 0.51798755,\n",
       "       0.67835972, 1.        , 0.99999951, 1.        , 0.51303218,\n",
       "       0.57459826, 0.70470018, 0.70063049, 0.44358671, 1.        ,\n",
       "       0.66436174, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.69235374, 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.99999839, 1.        ,\n",
       "       0.9999997 , 1.        , 1.        , 0.98271753, 1.        ,\n",
       "       1.        , 0.71660219, 0.99739713, 1.        , 1.        ,\n",
       "       1.        , 0.44453712, 0.99169951, 1.        , 1.        ,\n",
       "       0.66040933, 1.        , 0.59697136, 0.67986165, 1.        ,\n",
       "       1.        , 0.6461667 , 1.        , 0.70026609, 1.        ,\n",
       "       0.99096499, 1.        , 0.66924219, 0.99999999, 1.        ,\n",
       "       0.99995192, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.41623178, 1.        , 1.        ,\n",
       "       0.52902599, 1.        , 0.9999171 , 0.96271143, 1.        ,\n",
       "       1.        , 0.40513181, 0.99047632, 0.96335614, 0.71664707,\n",
       "       0.43433836, 1.        , 0.71160422, 0.99999999, 1.        ,\n",
       "       1.        , 1.        , 0.39988047, 1.        , 1.        ,\n",
       "       0.99963108, 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.60787754, 0.39961014, 1.        , 1.        , 1.        ,\n",
       "       0.99952333, 0.79758431, 1.        , 0.98847326, 1.        ,\n",
       "       1.        , 1.        , 0.63116879, 0.60083704, 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.58635205, 1.        ,\n",
       "       0.68092101, 0.9999841 , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1337.33334069, 1715.10139367],\n",
       "       [1715.10139367, 6023.3386793 ]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(gamma[:,1].reshape(-1,1), X).T.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_k = np.sum(gamma, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44702322, 0.55076245, 0.00221433])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_k/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(X, gamma):\n",
    "    \"\"\"\n",
    "    Performs M-step on GMM model\n",
    "    Each input is numpy array:\n",
    "    X: (N x d), data points\n",
    "    gamma: (N x C), distribution q(T)  \n",
    "    \n",
    "    Returns:\n",
    "    pi: (C)\n",
    "    mu: (C x d)\n",
    "    sigma: (C x d x d)\n",
    "    \"\"\"\n",
    "    N = X.shape[0] # number of objects\n",
    "    C = gamma.shape[1] # number of clusters\n",
    "    d = X.shape[1] # dimension of each object\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    N_k = np.sum(gamma, axis=0)\n",
    "    mu = np.divide(np.dot(gamma.T, X),gamma.sum(axis=0)[:,np.newaxis])\n",
    "    sigma = np.zeros((C,d,d),dtype=np.float)\n",
    "    for c in range(C):\n",
    "        diff = X - mu[c]\n",
    "        sigma[c,:,:] = np.multiply(gamma[:,c].reshape(-1,1), diff).T.dot(diff)/N_k[c]\n",
    "\n",
    "    pi = N_k / N\n",
    "    return pi, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task Task 2 (M-step: mu) is: 2.8993918820503817\n",
      "Current answer for task Task 2 (M-step: sigma) is: 5.9771052168975265\n",
      "Current answer for task Task 2 (M-step: pi) is: 0.5507624459218776\n",
      "[0.44702322 0.55076245 0.00221433]\n",
      "[[ 1.05852748  5.40759435]\n",
      " [ 2.16796132  2.89939188]\n",
      " [-1.33306197  1.41522785]]\n",
      "[[[ 0.70631457  1.00189734]\n",
      "  [ 1.00189734  3.09525744]]\n",
      "\n",
      " [[ 5.76353448  1.49049001]\n",
      "  [ 1.49049001  5.97710522]]\n",
      "\n",
      " [[ 0.0676037  -0.21186747]\n",
      "  [-0.21186747  3.29922798]]]\n"
     ]
    }
   ],
   "source": [
    "gamma = E_step(X, pi0, mu0, sigma0)\n",
    "pi, mu, sigma = M_step(X, gamma)\n",
    "grader.submit_m_step(pi, mu, sigma)\n",
    "print(pi)\n",
    "print(mu)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step2(X, gamma):\n",
    "    \"\"\"\n",
    "    Performs M-step on GMM model\n",
    "    Each input is numpy array:\n",
    "    X: (N x d), data points\n",
    "    gamma: (N x C), distribution q(T)  \n",
    "    \n",
    "    Returns:\n",
    "    pi: (C)\n",
    "    mu: (C x d)\n",
    "    sigma: (C x d x d)\n",
    "    \"\"\"\n",
    "    N = X.shape[0] # number of objects\n",
    "    C = gamma.shape[1] # number of clusters\n",
    "    d = X.shape[1] # dimension of each object\n",
    "    pi = np.zeros(C)\n",
    "    mu = np.zeros((C, d))\n",
    "    sigma = np.zeros((C, d, d))\n",
    "    for k in range(C):\n",
    "        q_sum = gamma[:,k].sum()\n",
    "        mu[k,:] = (X*gamma[:,k][:, np.newaxis]).sum(axis=0)/ q_sum\n",
    "        sigma[k,:] = np.sum([gamma[i,k] * np.outer(X[i] - mu[k], X[i] - mu[k]) for i in range(N)], axis=0) / q_sum\n",
    "        pi[k] = q_sum / N\n",
    "\n",
    "    return pi, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task Task 2 (M-step: mu) is: 2.899391882050384\n",
      "Current answer for task Task 2 (M-step: sigma) is: 5.9771052168975265\n",
      "Current answer for task Task 2 (M-step: pi) is: 0.5507624459218775\n",
      "[0.44702322 0.55076245 0.00221433]\n",
      "[[ 1.05852748  5.40759435]\n",
      " [ 2.16796132  2.89939188]\n",
      " [-1.33306197  1.41522785]]\n",
      "[[[ 0.70631457  1.00189734]\n",
      "  [ 1.00189734  3.09525744]]\n",
      "\n",
      " [[ 5.76353448  1.49049001]\n",
      "  [ 1.49049001  5.97710522]]\n",
      "\n",
      " [[ 0.0676037  -0.21186747]\n",
      "  [-0.21186747  3.29922798]]]\n"
     ]
    }
   ],
   "source": [
    "gamma = E_step(X, pi0, mu0, sigma0)\n",
    "pi, mu, sigma = M_step2(X, gamma)\n",
    "grader.submit_m_step(pi, mu, sigma)\n",
    "print(pi)\n",
    "print(mu)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 1)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma[:,0].reshape(-1,1).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need some function to track convergence. We will use variational lower bound $\\mathcal{L}$ for this purpose. We will stop our EM iterations when $\\mathcal{L}$ will saturate. Usually, you will need only about 10-20 iterations to converge. It is also useful to check that this function never decreases during training. If it does, you have a bug in your code.\n",
    "\n",
    "<b>Task 3:</b> Implement a function that will compute $\\mathcal{L}$ using template below.\n",
    "\n",
    "$$\\mathcal{L} = \\sum_{n=1}^{N} \\sum_{k=1}^{K} \\mathbb{E}[z_{n, k}] (\\log \\pi_k + \\log \\mathcal{N}(x_n | \\mu_k, \\sigma_k)) - \\sum_{n=1}^{N} \\sum_{k=1}^{K} \\mathbb{E}[z_{n, k}] \\log \\mathbb{E}[z_{n, k}]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vlb(X, pi, mu, sigma, gamma, mvn = multivariate_normal.pdf):\n",
    "    \"\"\"\n",
    "    Each input is numpy array:\n",
    "    X: (N x d), data points\n",
    "    gamma: (N x C), distribution q(T)  \n",
    "    pi: (C)\n",
    "    mu: (C x d)\n",
    "    sigma: (C x d x d)\n",
    "    mvn = multivariate_normal_pdf function\n",
    "        either use scipy, or my implementation\n",
    "        \n",
    "    Returns value of variational lower bound\n",
    "    \"\"\"\n",
    "    N = X.shape[0] # number of objects\n",
    "    C = gamma.shape[1] # number of clusters\n",
    "    d = X.shape[1] # dimension of each object\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    loss = 0\n",
    "    for c in range(C):\n",
    "        try:\n",
    "            #probX = multivariate_normal.pdf(X, mean = mu[c], cov=sigma[c,:,:])\n",
    "            probX = mvn(X, mean = mu[c], cov=sigma[c,:,:])\n",
    "            #print(probX)\n",
    "            val = np.dot(gamma[:,c],np.log(probX+1.0e-13) + np.log(pi[c]+1.0e-13))\n",
    "            #print(val)\n",
    "            loss +=  val\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            print(sigma)\n",
    "            print(sigma[c,:,:])\n",
    "            raise e\n",
    "            \n",
    "    loss -= np.multiply(gamma, np.log(gamma+1e-13)).sum()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 4]])"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 11],\n",
       "       [11, 25]])"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dot(a.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.235564744595834"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(a,np.log(a)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.16654849, 21.68698962],\n",
       "       [22.498753  , 26.06901626]])"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a.T, np.log(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.96911873779648"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.multiply(gamma, np.log(gamma+1e-9)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 3)"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05852748,  5.40759435],\n",
       "       [ 2.16796132,  2.89939188],\n",
       "       [-1.33306197,  1.41522785]])"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.70631457,  1.00189734],\n",
       "        [ 1.00189734,  3.09525744]],\n",
       "\n",
       "       [[ 5.76353448,  1.49049001],\n",
       "        [ 1.49049001,  5.97710522]],\n",
       "\n",
       "       [[ 0.0676037 , -0.21186747],\n",
       "        [-0.21186747,  3.29922798]]])"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44702322, 0.55076245, 0.00221433])"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.925387585498541"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 2\n",
    "(np.dot(gamma[:,c],np.log(multivariate_normal.pdf(X-X.max(axis=0), mean = mu[c], cov=sigma[c,:,:])+0.00001) + np.log(pi[c]+0.00001)))\n",
    "#(np.dot(gamma,np.log(multivariate_normal.pdf(X, mean = mu, cov=sigma)) + np.log(pi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1150.5132630339047"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task Task 3 (VLB) is: -1213.973437451592\n"
     ]
    }
   ],
   "source": [
    "pi, mu, sigma = pi0, mu0, sigma0\n",
    "gamma = E_step(X, pi, mu, sigma)\n",
    "pi, mu, sigma = M_step(X, gamma)\n",
    "loss = compute_vlb(X, pi, mu, sigma, gamma)\n",
    "grader.submit_VLB(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46383545 0.52768499 0.00847956] [[ 1.07499213  5.85685648]\n",
      " [ 2.22864219  2.45133965]\n",
      " [-1.22344612  0.84643644]] [[[ 0.68405518  0.17863387]\n",
      "  [ 0.17863387  1.3030211 ]]\n",
      "\n",
      " [[ 5.86816538  2.66859884]\n",
      "  [ 2.66859884  5.09531312]]\n",
      "\n",
      " [[ 0.02252806 -0.06231391]\n",
      "  [-0.06231391  0.97861765]]] 1150.5132630339047\n"
     ]
    }
   ],
   "source": [
    "pi, mu, sigma = pi0, mu0, sigma0\n",
    "gamma = E_step(X, pi, mu, sigma)\n",
    "pi, mu, sigma = M_step(X, gamma)\n",
    "loss = compute_vlb(X, pi, mu, sigma, gamma)\n",
    "gamma = E_step(X, pi, mu, sigma)\n",
    "pi, mu, sigma = M_step(X, gamma)\n",
    "loss = compute_vlb(X, pi, mu, sigma, gamma)\n",
    "gamma = E_step(X, pi, mu, sigma)\n",
    "pi, mu, sigma = M_step(X, gamma)\n",
    "loss = compute_vlb(X, pi, mu, sigma, gamma)\n",
    "gamma = E_step(X, pi, mu, sigma)\n",
    "pi, mu, sigma = M_step(X, gamma)\n",
    "loss = compute_vlb(X, pi, mu, sigma, gamma)\n",
    "print(pi, mu, sigma , loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.7052961 , 0.47317406],\n",
       "        [0.47317406, 5.95373982]],\n",
       "\n",
       "       [[3.23074395, 0.14994485],\n",
       "        [0.14994485, 5.12252562]],\n",
       "\n",
       "       [[4.14966413, 0.80463019],\n",
       "        [0.80463019, 6.54800119]]])"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have E step, M step and VLB, we can implement training loop. We will start at random values of $\\pi$, $\\mu$ and $\\Sigma$, train until $\\mathcal{L}$ stops changing and return the resulting points. We also know that EM algorithm sometimes stops at local optima. To avoid this we should restart algorithm multiple times from different starting positions. Each training trial should stop either when maximum number of iterations is reached or when relative improvement is smaller than given tolerance ($|\\frac{\\mathcal{L}_i-\\mathcal{L}_{i-1}}{\\mathcal{L}_{i-1}}| \\le \\text{rtol}$).\n",
    "\n",
    "Remember, that values of $\\pi$ that you generate must be non-negative and sum up to 1. Also, $\\Sigma$ matrices must be symmetric and positive semi-definite. If you don't know how to generate those matrices, you can use $\\Sigma=I$ as initialization.\n",
    "\n",
    "You will also sometimes get numerical errors because of component collapsing. The easiest way to deal with this problems is to simply restart the procedure.\n",
    "\n",
    "<b>Task 4:</b> Implement training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.62533136, 8.08548733])"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.63390585 -6.68593365]\n",
      " [-1.67585513  3.31208141]\n",
      " [-6.26770647 -3.93645941]]\n",
      "-17.88777910933173\n"
     ]
    }
   ],
   "source": [
    "pi0 = np.random.randn(3,2)*X.max(axis=0)/1.5\n",
    "print(pi0)\n",
    "print(pi0.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma0 = np.zeros((10,2,2), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma0[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.85269356 0.80625096]\n",
      "  [0.76757971 0.2579088 ]]\n",
      "\n",
      " [[0.17917993 0.31599937]\n",
      "  [0.08684136 0.68370508]]\n",
      "\n",
      " [[0.6261453  0.65986771]\n",
      "  [0.84791466 0.52690943]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1.37712691, 0.86244949],\n",
       "        [0.86244949, 0.65569556]],\n",
       "\n",
       "       [[0.13196105, 0.2316106 ],\n",
       "        [0.2316106 , 0.47499406]],\n",
       "\n",
       "       [[0.82748333, 0.87860829],\n",
       "        [0.87860829, 0.99659281]]])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C,d  = 3,2\n",
    "\n",
    "sigma_ = np.random.rand(C, d, d)\n",
    "print(sigma_)\n",
    "sigma = np.array([np.dot(A, A.T) for A in sigma_])\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[3.4961043  1.27408894]\n",
      "  [1.27408894 5.6830558 ]]\n",
      "\n",
      " [[6.56120847 1.18371909]\n",
      "  [1.18371909 5.48737927]]\n",
      "\n",
      " [[2.3791707  0.67255181]\n",
      "  [0.67255181 6.10281444]]]\n",
      "[11.72733798 14.41602593  9.82708876]\n",
      "[[[0.29811576 0.10864264]\n",
      "  [0.10864264 0.48459896]]\n",
      "\n",
      " [[0.45513295 0.08211133]\n",
      "  [0.08211133 0.38064438]]\n",
      "\n",
      " [[0.24210331 0.06843856]\n",
      "  [0.06843856 0.62101957]]]\n"
     ]
    }
   ],
   "source": [
    "sigma0 = np.zeros((C,d,d), dtype=np.float)\n",
    "for c in range(C):\n",
    "    sigma0[c,:,:] = np.cov(X[np.random.randint(0,X.shape[0],size=int(X.shape[0]/3)),:].T)\n",
    "    \n",
    "print(sigma0)\n",
    "print(sigma0.sum(axis=1).sum(axis=1))\n",
    "print(sigma0/sigma0.sum(axis=1).sum(axis=1)[:,np.newaxis,np.newaxis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_EM(X, C, rtol=1e-3, max_iter=100, restarts=10):\n",
    "    '''\n",
    "    Starts with random initialization *restarts* times\n",
    "    Runs optimization until saturation with *rtol* reached\n",
    "    or *max_iter* iterations were made.\n",
    "    \n",
    "    X: (N, d), data points\n",
    "    C: int, number of clusters\n",
    "    '''\n",
    "    N = X.shape[0] # number of objects\n",
    "    d = X.shape[1] # dimension of each object\n",
    "    best_loss = None\n",
    "    best_pi = None\n",
    "    best_mu = None\n",
    "    best_sigma = None\n",
    "\n",
    "    for _ in range(restarts):\n",
    "        \n",
    "        print(\"\\n New Run \\n\\n\")\n",
    "        try:\n",
    "            ### YOUR CODE HERE\n",
    "            last_loss = None\n",
    "            numiter = 0\n",
    "            \n",
    "            \n",
    "            pi = np.random.rand(3)\n",
    "            pi = pi0/pi0.sum()\n",
    "            #print(pi)\n",
    "            #mu = np.random.randn(3,2)*X.mean()\n",
    "            #print(mu)\n",
    "            sigma = np.zeros((C,d,d), dtype=np.float)\n",
    "            for c in range(C):\n",
    "                sigma[c,:,:] = np.cov(X[np.random.randint(0,X.shape[0],size=int(X.shape[0]/3)),:].T)\n",
    "\n",
    "            sigma /= sigma.sum(axis=1).sum(axis=1)[:,np.newaxis,np.newaxis]\n",
    "            #sigma = samples['sigma0']\n",
    "    \n",
    "            sigma_ = np.random.rand(C, d, d)\n",
    "            sigma = np.array([np.dot(A, A.T) for A in sigma_])\n",
    "            #print(sigma)\n",
    "            \n",
    "            \n",
    "            pi = np.array([1.0/C]*C,dtype=np.float32)\n",
    "            mu = np.random.rand(C, d)\n",
    "            #sigma_ = np.random.rand(C, d, d)\n",
    "            #sigma = np.array([np.dot(A, A.T) for A in sigma_])\n",
    "            \n",
    "            print('init values')\n",
    "            print(pi)\n",
    "            print(mu)\n",
    "            print(sigma)\n",
    "            \n",
    "            while True:\n",
    "                \n",
    "                gamma = E_step(X, pi, mu, sigma)\n",
    "                pi, mu, sigma = M_step(X, gamma)\n",
    "                loss = -compute_vlb(X, pi, mu, sigma, gamma)\n",
    "                \n",
    "                print(\"iter{}, loss {}\".format(numiter, loss))\n",
    "\n",
    "                \n",
    "                if best_loss is None or loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_pi = pi\n",
    "                    best_mu = mu\n",
    "                    best_sigma = sigma\n",
    "                \n",
    "                if last_loss is not None and loss > last_loss: \n",
    "                    raise Exception(\"error\", \"last_loss: {}, this_loss: {}\".format(last_loss, loss))\n",
    "                \n",
    "                if (last_loss is not None) and last_loss - loss < rtol:\n",
    "                    print(loss)\n",
    "                    print(last_loss)\n",
    "                    print(\"loss converged: {}\".format(last_loss - loss))\n",
    "                    break\n",
    "                \n",
    "                        \n",
    "                        \n",
    "                if numiter == max_iter:\n",
    "                    break\n",
    "                    \n",
    "                numiter += 1\n",
    "                last_loss = loss\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "        print(-best_loss)\n",
    "        print(best_pi)\n",
    "        print(best_mu)\n",
    "        print(best_sigma)\n",
    "    return -best_loss, best_pi, best_mu, best_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " New Run \n",
      "\n",
      "\n",
      "init values\n",
      "[0.33333334 0.33333334 0.33333334]\n",
      "[[0.81251478 0.50173078]\n",
      " [0.22155087 0.91820349]\n",
      " [0.24355623 0.97425982]]\n",
      "[[[1.0876924  0.68786154]\n",
      "  [0.68786154 1.00268594]]\n",
      "\n",
      " [[0.36672547 0.67002781]\n",
      "  [0.67002781 1.41347395]]\n",
      "\n",
      " [[0.09134439 0.14879352]\n",
      "  [0.14879352 0.25820822]]]\n",
      "iter0, loss 1281.9596919304095\n",
      "iter1, loss 1227.1927293143876\n",
      "iter2, loss 1210.662643316836\n",
      "iter3, loss 1191.5178209949772\n",
      "iter4, loss 1170.7695599037993\n",
      "iter5, loss 1157.477574573195\n",
      "iter6, loss 1150.8036553223785\n",
      "iter7, loss 1145.952785271049\n",
      "iter8, loss 1141.4540173329026\n",
      "iter9, loss 1137.4630948149268\n",
      "iter10, loss 1134.3661146462398\n",
      "iter11, loss 1132.186574816456\n",
      "iter12, loss 1130.7857134767048\n",
      "iter13, loss 1129.9840115311024\n",
      "iter14, loss 1129.5777632663621\n",
      "iter15, loss 1129.3890384213037\n",
      "iter16, loss 1129.3048197264145\n",
      "iter17, loss 1129.2674393773646\n",
      "iter18, loss 1129.2505840721947\n",
      "iter19, loss 1129.2427490452724\n",
      "iter20, loss 1129.2389434977667\n",
      "iter21, loss 1129.236985772671\n",
      "iter22, loss 1129.235907266283\n",
      "iter23, loss 1129.2352683038064\n",
      "1129.2352683038064\n",
      "1129.235907266283\n",
      "loss converged: 0.0006389624766143243\n",
      "-1129.2352683038064\n",
      "[0.44192096 0.53664458 0.02143446]\n",
      "[[2.31305839 1.88204958]\n",
      " [1.1733893  5.86914677]\n",
      " [0.57777052 1.67801095]]\n",
      "[[[6.69127994 3.51812896]\n",
      "  [3.51812896 3.8357016 ]]\n",
      "\n",
      " [[0.95415243 0.15248322]\n",
      "  [0.15248322 1.05723284]]\n",
      "\n",
      " [[0.19532124 0.37230678]\n",
      "  [0.37230678 0.71659537]]]\n",
      "\n",
      " New Run \n",
      "\n",
      "\n",
      "init values\n",
      "[0.33333334 0.33333334 0.33333334]\n",
      "[[0.08365917 0.82550179]\n",
      " [0.00587812 0.1953386 ]\n",
      " [0.72277746 0.48530475]]\n",
      "[[[0.85312666 0.143167  ]\n",
      "  [0.143167   0.02852534]]\n",
      "\n",
      " [[0.34949965 0.56503373]\n",
      "  [0.56503373 1.17790747]]\n",
      "\n",
      " [[0.50509051 0.55340164]\n",
      "  [0.55340164 0.96774937]]]\n",
      "iter0, loss 1255.9110305613963\n",
      "iter1, loss 1194.5546056677076\n",
      "iter2, loss 1178.6126554874522\n",
      "iter3, loss 1169.0462960787647\n",
      "iter4, loss 1158.298988605022\n",
      "iter5, loss 1145.5163806084095\n",
      "iter6, loss 1134.4443137981266\n",
      "iter7, loss 1128.144952965272\n",
      "iter8, loss 1125.9477786520097\n",
      "iter9, loss 1125.351354439533\n",
      "iter10, loss 1125.1195533703808\n",
      "iter11, loss 1124.898524079355\n",
      "iter12, loss 1124.5169222538786\n",
      "iter13, loss 1123.728420515844\n",
      "iter14, loss 1122.1376821449928\n",
      "iter15, loss 1119.6695629853277\n",
      "iter16, loss 1117.4182973941504\n",
      "iter17, loss 1116.0918989434574\n",
      "iter18, loss 1115.2543537386484\n",
      "iter19, loss 1114.4839833024885\n",
      "iter20, loss 1113.6269776565075\n",
      "iter21, loss 1112.8093931823814\n",
      "iter22, loss 1112.019445897152\n",
      "iter23, loss 1110.9170684510188\n",
      "iter24, loss 1108.8427629053415\n",
      "iter25, loss 1104.9409184678186\n",
      "iter26, loss 1099.576958390598\n",
      "iter27, loss 1095.0383045163353\n",
      "iter28, loss 1091.4308780323004\n",
      "iter29, loss 1088.426791378692\n",
      "iter30, loss 1085.8241805487964\n",
      "iter31, loss 1083.4312113291235\n",
      "iter32, loss 1081.0126661360075\n",
      "iter33, loss 1078.1869866233933\n",
      "iter34, loss 1074.3387881265564\n",
      "iter35, loss 1069.7498933472307\n",
      "iter36, loss 1066.6323492876475\n",
      "iter37, loss 1065.3474129290971\n",
      "iter38, loss 1064.6310425985985\n",
      "iter39, loss 1064.1758067763587\n",
      "iter40, loss 1063.9448250118135\n",
      "iter41, loss 1063.8556110795537\n",
      "iter42, loss 1063.8263790784379\n",
      "iter43, loss 1063.8169245637648\n",
      "iter44, loss 1063.8135939147037\n",
      "iter45, loss 1063.8122871480418\n",
      "iter46, loss 1063.8117289918316\n",
      "1063.8117289918316\n",
      "1063.8122871480418\n",
      "loss converged: 0.0005581562102179305\n",
      "-1063.8117289918316\n",
      "[0.34153103 0.55110726 0.10736171]\n",
      "[[0.92082919 0.96431765]\n",
      " [1.2229296  5.82899214]\n",
      " [6.2946936  4.42975356]]\n",
      "[[[ 1.4984994  -0.3735356 ]\n",
      "  [-0.3735356   1.42436634]]\n",
      "\n",
      " [[ 0.94377647  0.06757822]\n",
      "  [ 0.06757822  1.1088653 ]]\n",
      "\n",
      " [[ 1.71322452  1.3948262 ]\n",
      "  [ 1.3948262   1.32515653]]]\n",
      "\n",
      " New Run \n",
      "\n",
      "\n",
      "init values\n",
      "[0.33333334 0.33333334 0.33333334]\n",
      "[[0.66891402 0.90109112]\n",
      " [0.79174607 0.04218808]\n",
      " [0.51561009 0.07355137]]\n",
      "[[[0.60266105 0.50645655]\n",
      "  [0.50645655 0.9128266 ]]\n",
      "\n",
      " [[0.2125232  0.42306149]\n",
      "  [0.42306149 0.84898624]]\n",
      "\n",
      " [[0.93752486 1.07268584]\n",
      "  [1.07268584 1.230904  ]]]\n",
      "iter0, loss 1232.6845654161052\n",
      "iter1, loss 1230.8696047655985\n",
      "iter2, loss 1230.4546268064657\n",
      "iter3, loss 1230.1706744572423\n",
      "iter4, loss 1229.9303671200614\n",
      "iter5, loss 1229.7089515234607\n",
      "iter6, loss 1229.3743354550788\n",
      "iter7, loss 1228.5110111557533\n",
      "iter8, loss 1226.8213672828479\n",
      "iter9, loss 1225.5503505111697\n",
      "iter10, loss 1224.3528251311034\n",
      "iter11, loss 1221.5463629523542\n",
      "iter12, loss 1216.5966328995141\n",
      "iter13, loss 1213.459469057261\n",
      "iter14, loss 1211.8970866311354\n",
      "iter15, loss 1211.0401758423525\n",
      "iter16, loss 1210.2913290998194\n",
      "iter17, loss 1209.4314225423489\n",
      "iter18, loss 1208.6986224483448\n",
      "iter19, loss 1208.2510714855289\n",
      "iter20, loss 1207.7865266275146\n",
      "iter21, loss 1207.1257612661516\n",
      "iter22, loss 1206.5760145852005\n",
      "iter23, loss 1206.2963693326028\n",
      "iter24, loss 1206.0850181539317\n",
      "iter25, loss 1205.8165734488296\n",
      "iter26, loss 1205.5201715853052\n",
      "iter27, loss 1205.3300626078494\n",
      "iter28, loss 1205.2218471183428\n",
      "iter29, loss 1205.1394585018077\n",
      "iter30, loss 1205.0715849599512\n",
      "iter31, loss 1205.021194339012\n",
      "iter32, loss 1204.9879289514713\n",
      "iter33, loss 1204.9669727101189\n",
      "iter34, loss 1204.9534597836848\n",
      "iter35, loss 1204.9442397420287\n",
      "iter36, loss 1204.937537247037\n",
      "iter37, loss 1204.9323590491877\n",
      "iter38, loss 1204.9281237905034\n",
      "iter39, loss 1204.9244676054727\n",
      "iter40, loss 1204.9211424309804\n",
      "iter41, loss 1204.917959222031\n",
      "iter42, loss 1204.9147518793259\n",
      "iter43, loss 1204.9113487012758\n",
      "iter44, loss 1204.9075420657223\n",
      "iter45, loss 1204.903046292385\n",
      "iter46, loss 1204.8974278024175\n",
      "iter47, loss 1204.8899769759537\n",
      "iter48, loss 1204.879457676386\n",
      "iter49, loss 1204.86359695177\n",
      "iter50, loss 1204.8380305286287\n",
      "iter51, loss 1204.7942291605848\n",
      "iter52, loss 1204.7163300701827\n",
      "iter53, loss 1204.580909639131\n",
      "iter54, loss 1204.3742847839587\n",
      "iter55, loss 1204.1239902226002\n",
      "iter56, loss 1203.8754032009338\n",
      "iter57, loss 1203.6403968363059\n",
      "iter58, loss 1203.4052097825609\n",
      "iter59, loss 1203.139452048245\n",
      "iter60, loss 1202.7783301161307\n",
      "iter61, loss 1202.1862958893787\n",
      "iter62, loss 1201.146520781461\n",
      "iter63, loss 1199.5574688136749\n",
      "iter64, loss 1197.7628668632958\n",
      "iter65, loss 1196.2035600082977\n",
      "iter66, loss 1194.8840901908386\n",
      "iter67, loss 1193.5280489312665\n",
      "iter68, loss 1191.6006707144923\n",
      "iter69, loss 1187.8432993742535\n",
      "iter70, loss 1180.4209153389381\n",
      "iter71, loss 1171.443724528719\n",
      "iter72, loss 1164.6362051221774\n",
      "iter73, loss 1159.9649019067315\n",
      "iter74, loss 1157.3935783265365\n",
      "iter75, loss 1156.2882137742097\n",
      "iter76, loss 1155.8563166031563\n",
      "iter77, loss 1155.674957387653\n",
      "iter78, loss 1155.5833044354506\n",
      "iter79, loss 1155.5226263703223\n",
      "iter80, loss 1155.4691813290756\n",
      "iter81, loss 1155.411357083447\n",
      "iter82, loss 1155.3419052921972\n",
      "iter83, loss 1155.255738371251\n",
      "iter84, loss 1155.150637317928\n",
      "iter85, loss 1155.029913537175\n",
      "iter86, loss 1154.904329158894\n",
      "iter87, loss 1154.788218241385\n",
      "iter88, loss 1154.690912887464\n",
      "iter89, loss 1154.6134638987473\n",
      "iter90, loss 1154.5524614856774\n",
      "iter91, loss 1154.5038565517514\n",
      "iter92, loss 1154.4642549452155\n",
      "iter93, loss 1154.43098859521\n",
      "iter94, loss 1154.4019125657944\n",
      "iter95, loss 1154.3751593487766\n",
      "iter96, loss 1154.348833368952\n",
      "iter97, loss 1154.3205284843666\n",
      "iter98, loss 1154.2863751802847\n",
      "iter99, loss 1154.2388224862932\n",
      "iter100, loss 1154.160802357071\n",
      "-1063.8117289918316\n",
      "[0.34153103 0.55110726 0.10736171]\n",
      "[[0.92082919 0.96431765]\n",
      " [1.2229296  5.82899214]\n",
      " [6.2946936  4.42975356]]\n",
      "[[[ 1.4984994  -0.3735356 ]\n",
      "  [-0.3735356   1.42436634]]\n",
      "\n",
      " [[ 0.94377647  0.06757822]\n",
      "  [ 0.06757822  1.1088653 ]]\n",
      "\n",
      " [[ 1.71322452  1.3948262 ]\n",
      "  [ 1.3948262   1.32515653]]]\n",
      "\n",
      " New Run \n",
      "\n",
      "\n",
      "init values\n",
      "[0.33333334 0.33333334 0.33333334]\n",
      "[[0.46055577 0.73424175]\n",
      " [0.52472883 0.14801894]\n",
      " [0.70659114 0.73470014]]\n",
      "[[[0.17665559 0.30309731]\n",
      "  [0.30309731 0.67905238]]\n",
      "\n",
      " [[0.59324077 0.78996065]\n",
      "  [0.78996065 1.06936031]]\n",
      "\n",
      " [[0.21420575 0.41038094]\n",
      "  [0.41038094 0.85686693]]]\n",
      "iter0, loss 1268.6082229910583\n",
      "iter1, loss 1232.6171050295632\n",
      "iter2, loss 1224.286135239381\n",
      "iter3, loss 1218.8602451983409\n",
      "iter4, loss 1215.6179146176294\n",
      "iter5, loss 1213.9832227729792\n",
      "iter6, loss 1213.13820953887\n",
      "iter7, loss 1212.6072561490803\n",
      "iter8, loss 1212.2205684452067\n",
      "iter9, loss 1211.91905925168\n",
      "iter10, loss 1211.6773268479606\n",
      "iter11, loss 1211.4732270995887\n",
      "iter12, loss 1211.2804696658372\n",
      "iter13, loss 1211.0674197757655\n",
      "iter14, loss 1210.788595072017\n",
      "iter15, loss 1210.3630139844172\n",
      "iter16, loss 1209.6360862468473\n",
      "iter17, loss 1208.34943543096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter18, loss 1206.187434171692\n",
      "iter19, loss 1202.7368937621197\n",
      "iter20, loss 1197.2578155446997\n",
      "iter21, loss 1190.3032909397898\n",
      "iter22, loss 1183.4505277426474\n",
      "iter23, loss 1176.5148030582097\n",
      "iter24, loss 1169.728318567567\n",
      "iter25, loss 1164.281109026612\n",
      "iter26, loss 1161.1786671521081\n",
      "iter27, loss 1159.8857231161398\n",
      "iter28, loss 1159.4020069379571\n",
      "iter29, loss 1159.1648604859615\n",
      "iter30, loss 1158.947202894053\n",
      "iter31, loss 1158.7530531748357\n",
      "iter32, loss 1158.6583059546601\n",
      "iter33, loss 1158.621515628318\n",
      "iter34, loss 1158.5981472550234\n",
      "iter35, loss 1158.571638468063\n",
      "iter36, loss 1158.529069720254\n",
      "iter37, loss 1158.4455684060101\n",
      "iter38, loss 1158.2987368070678\n",
      "iter39, loss 1158.1913528536413\n",
      "iter40, loss 1158.1608075036092\n",
      "iter41, loss 1158.1477186905167\n",
      "iter42, loss 1158.1384758782945\n",
      "iter43, loss 1158.1298008057556\n",
      "iter44, loss 1158.119841060771\n",
      "iter45, loss 1158.106316978367\n",
      "iter46, loss 1158.0849955591584\n",
      "iter47, loss 1158.046842093828\n",
      "iter48, loss 1157.9707129227822\n",
      "iter49, loss 1157.7647188324497\n",
      "iter50, loss 1156.0013261897207\n",
      "singular matrix\n",
      "-1063.8117289918316\n",
      "[0.34153103 0.55110726 0.10736171]\n",
      "[[0.92082919 0.96431765]\n",
      " [1.2229296  5.82899214]\n",
      " [6.2946936  4.42975356]]\n",
      "[[[ 1.4984994  -0.3735356 ]\n",
      "  [-0.3735356   1.42436634]]\n",
      "\n",
      " [[ 0.94377647  0.06757822]\n",
      "  [ 0.06757822  1.1088653 ]]\n",
      "\n",
      " [[ 1.71322452  1.3948262 ]\n",
      "  [ 1.3948262   1.32515653]]]\n",
      "\n",
      " New Run \n",
      "\n",
      "\n",
      "init values\n",
      "[0.33333334 0.33333334 0.33333334]\n",
      "[[0.47222496 0.58040267]\n",
      " [0.12414782 0.57795626]\n",
      " [0.99567633 0.6273643 ]]\n",
      "[[[0.28759855 0.41563425]\n",
      "  [0.41563425 0.68885661]]\n",
      "\n",
      " [[0.09160351 0.21794538]\n",
      "  [0.21794538 0.51898571]]\n",
      "\n",
      " [[1.29101325 0.90965114]\n",
      "  [0.90965114 0.69571632]]]\n",
      "iter0, loss 1172.7550629347238\n",
      "iter1, loss 1143.8119140648348\n",
      "iter2, loss 1142.6007818667972\n",
      "iter3, loss 1142.2787347965884\n",
      "iter4, loss 1142.1636412322814\n",
      "iter5, loss 1142.0792387296715\n",
      "iter6, loss 1141.958941262275\n",
      "iter7, loss 1141.5511405376078\n",
      "iter8, loss 1136.693604640089\n",
      "iter9, loss 1134.3788388529995\n",
      "iter10, loss 1132.7265107930411\n",
      "iter11, loss 1131.513808120659\n",
      "iter12, loss 1131.2307119388474\n",
      "iter13, loss 1130.9288597158918\n",
      "iter14, loss 1130.5966265892653\n",
      "iter15, loss 1130.2352107452107\n",
      "iter16, loss 1129.8443872845173\n",
      "iter17, loss 1129.4208379180423\n",
      "iter18, loss 1128.957545697072\n",
      "iter19, loss 1128.4452548073136\n",
      "iter20, loss 1127.877389046868\n",
      "iter21, loss 1127.258043127207\n",
      "iter22, loss 1126.6077256272167\n",
      "iter23, loss 1125.960932923875\n",
      "iter24, loss 1125.3593981642175\n",
      "iter25, loss 1124.846196398342\n",
      "iter26, loss 1124.4543905281816\n",
      "iter27, loss 1124.1910255988396\n",
      "iter28, loss 1124.0344642048785\n",
      "iter29, loss 1123.9502385293054\n",
      "iter30, loss 1123.9080090773646\n",
      "iter31, loss 1123.887769926945\n",
      "iter32, loss 1123.8783333914973\n",
      "iter33, loss 1123.8740061428866\n",
      "iter34, loss 1123.8720418917962\n",
      "iter35, loss 1123.8711559015833\n",
      "1123.8711559015833\n",
      "1123.8720418917962\n",
      "loss converged: 0.000885990212964316\n",
      "-1063.8117289918316\n",
      "[0.34153103 0.55110726 0.10736171]\n",
      "[[0.92082919 0.96431765]\n",
      " [1.2229296  5.82899214]\n",
      " [6.2946936  4.42975356]]\n",
      "[[[ 1.4984994  -0.3735356 ]\n",
      "  [-0.3735356   1.42436634]]\n",
      "\n",
      " [[ 0.94377647  0.06757822]\n",
      "  [ 0.06757822  1.1088653 ]]\n",
      "\n",
      " [[ 1.71322452  1.3948262 ]\n",
      "  [ 1.3948262   1.32515653]]]\n",
      "\n",
      " New Run \n",
      "\n",
      "\n",
      "init values\n",
      "[0.33333334 0.33333334 0.33333334]\n",
      "[[0.84533706 0.85027279]\n",
      " [0.74425483 0.42505244]\n",
      " [0.12308375 0.86677962]]\n",
      "[[[1.06789946 0.70680597]\n",
      "  [0.70680597 0.49521025]]\n",
      "\n",
      " [[0.29260567 0.46240082]\n",
      "  [0.46240082 0.92157261]]\n",
      "\n",
      " [[0.04455502 0.11176378]\n",
      "  [0.11176378 0.38392483]]]\n",
      "iter0, loss 1211.9441845877645\n",
      "iter1, loss 1137.4145106973638\n",
      "iter2, loss 1124.7374607937472\n",
      "iter3, loss 1113.8076507992748\n",
      "iter4, loss 1103.4656093655212\n",
      "iter5, loss 1096.9799272738894\n",
      "iter6, loss 1092.7817894655489\n",
      "iter7, loss 1089.0328384795912\n",
      "iter8, loss 1085.7385185395817\n",
      "iter9, loss 1083.030320525449\n",
      "iter10, loss 1080.6022766252772\n",
      "iter11, loss 1078.1891508943045\n",
      "iter12, loss 1075.6608250734685\n",
      "iter13, loss 1072.9667791654913\n",
      "iter14, loss 1070.2089958309575\n",
      "iter15, loss 1067.7467662178144\n",
      "iter16, loss 1065.9797626592047\n",
      "iter17, loss 1064.939047370171\n",
      "iter18, loss 1064.385953719997\n",
      "iter19, loss 1064.1013203616176\n",
      "iter20, loss 1063.9562314765662\n",
      "iter21, loss 1063.8829753999144\n",
      "iter22, loss 1063.8464167606494\n",
      "iter23, loss 1063.828372531492\n",
      "iter24, loss 1063.8195455115638\n",
      "iter25, loss 1063.8152559296668\n",
      "iter26, loss 1063.8131811648686\n",
      "iter27, loss 1063.8121809480451\n",
      "iter28, loss 1063.811699852713\n",
      "1063.811699852713\n",
      "1063.8121809480451\n",
      "loss converged: 0.0004810953321339184\n",
      "-1063.811699852713\n",
      "[0.10727386 0.34221837 0.55050776]\n",
      "[[6.29727181 4.43163691]\n",
      " [0.92130628 0.96906964]\n",
      " [1.22331714 5.83152166]]\n",
      "[[[ 1.7062103   1.3897418 ]\n",
      "  [ 1.3897418   1.3215502 ]]\n",
      "\n",
      " [[ 1.49927144 -0.37267466]\n",
      "  [-0.37267466  1.43398316]]\n",
      "\n",
      " [[ 0.94316582  0.0670025 ]\n",
      "  [ 0.0670025   1.10374237]]]\n",
      "\n",
      " New Run \n",
      "\n",
      "\n",
      "init values\n",
      "[0.33333334 0.33333334 0.33333334]\n",
      "[[0.71026447 0.08292874]\n",
      " [0.53301434 0.48430778]\n",
      " [0.22717911 0.24385536]]\n",
      "[[[0.94068968 0.26424019]\n",
      "  [0.26424019 0.38220954]]\n",
      "\n",
      " [[1.5016323  1.00397479]\n",
      "  [1.00397479 0.84959494]]\n",
      "\n",
      " [[0.61161664 0.49710371]\n",
      "  [0.49710371 0.4072986 ]]]\n",
      "iter0, loss 1217.3397710028746\n",
      "iter1, loss 1161.6212881399115\n",
      "iter2, loss 1155.5561693942188\n",
      "iter3, loss 1150.7335563653908\n",
      "iter4, loss 1146.0754944591854\n",
      "iter5, loss 1141.68147503134\n",
      "iter6, loss 1137.5836619547354\n",
      "iter7, loss 1134.3522324218725\n",
      "iter8, loss 1132.577505537847\n",
      "iter9, loss 1131.6389420568541\n",
      "iter10, loss 1130.7415111349856\n",
      "iter11, loss 1129.6120830838158\n",
      "iter12, loss 1128.3484351450775\n",
      "iter13, loss 1127.3566688316218\n",
      "iter14, loss 1126.7645510898483\n",
      "iter15, loss 1126.4286929983543\n",
      "iter16, loss 1126.228412445395\n",
      "iter17, loss 1126.0927692036698\n",
      "iter18, loss 1125.9826505068781\n",
      "iter19, loss 1125.8764816858497\n",
      "iter20, loss 1125.7599097549814\n",
      "iter21, loss 1125.6190973774183\n",
      "iter22, loss 1125.4359609885496\n",
      "iter23, loss 1125.184286554577\n",
      "iter24, loss 1124.8292577963255\n",
      "iter25, loss 1124.3428493218414\n",
      "iter26, loss 1123.7566181205152\n",
      "iter27, loss 1123.2116519967021\n",
      "iter28, loss 1122.8433507030506\n",
      "iter29, loss 1122.6278528629166\n",
      "iter30, loss 1122.4852490850062\n",
      "iter31, loss 1122.377841401914\n",
      "iter32, loss 1122.298606223632\n",
      "iter33, loss 1122.2487524441128\n",
      "iter34, loss 1122.2241814642505\n",
      "iter35, loss 1122.2148187399002\n",
      "iter36, loss 1122.2119257909194\n",
      "iter37, loss 1122.2111475809043\n",
      "1122.2111475809043\n",
      "1122.2119257909194\n",
      "loss converged: 0.0007782100151416671\n",
      "-1063.811699852713\n",
      "[0.10727386 0.34221837 0.55050776]\n",
      "[[6.29727181 4.43163691]\n",
      " [0.92130628 0.96906964]\n",
      " [1.22331714 5.83152166]]\n",
      "[[[ 1.7062103   1.3897418 ]\n",
      "  [ 1.3897418   1.3215502 ]]\n",
      "\n",
      " [[ 1.49927144 -0.37267466]\n",
      "  [-0.37267466  1.43398316]]\n",
      "\n",
      " [[ 0.94316582  0.0670025 ]\n",
      "  [ 0.0670025   1.10374237]]]\n",
      "\n",
      " New Run \n",
      "\n",
      "\n",
      "init values\n",
      "[0.33333334 0.33333334 0.33333334]\n",
      "[[0.92329507 0.93711214]\n",
      " [0.99168488 0.58997355]\n",
      " [0.57345388 0.80610282]]\n",
      "[[[0.02359368 0.03851879]\n",
      "  [0.03851879 0.08982612]]\n",
      "\n",
      " [[0.97957376 0.83023274]\n",
      "  [0.83023274 1.03309616]]\n",
      "\n",
      " [[0.74325648 0.55530831]\n",
      "  [0.55530831 0.95142519]]]\n",
      "iter0, loss 1148.3956556939438\n",
      "iter1, loss 1140.825231977798\n",
      "iter2, loss 1137.221641363738\n",
      "iter3, loss 1134.199211289665\n",
      "iter4, loss 1131.2242709057255\n",
      "iter5, loss 1127.9286170015994\n",
      "iter6, loss 1124.838071401397\n",
      "iter7, loss 1122.6711752036013\n",
      "iter8, loss 1121.3320962189425\n",
      "iter9, loss 1120.4279335828717\n",
      "iter10, loss 1119.6815322020518\n",
      "iter11, loss 1118.9645134222833\n",
      "iter12, loss 1118.2398574814924\n",
      "iter13, loss 1117.548120400637\n",
      "iter14, loss 1116.9879296098302\n",
      "iter15, loss 1116.6115862939273\n",
      "iter16, loss 1116.3633781431422\n",
      "iter17, loss 1116.1748289039087\n",
      "iter18, loss 1116.0215519838382\n",
      "iter19, loss 1115.9033250871662\n",
      "iter20, loss 1115.8173408708938\n",
      "iter21, loss 1115.7501291630037\n",
      "iter22, loss 1115.6880968415908\n",
      "iter23, loss 1115.6246774248482\n",
      "iter24, loss 1115.5585752650657\n",
      "iter25, loss 1115.490709663079\n",
      "iter26, loss 1115.422411235809\n",
      "iter27, loss 1115.3543273489975\n",
      "iter28, loss 1115.2857072473253\n",
      "iter29, loss 1115.2139480450487\n",
      "iter30, loss 1115.1340198995044\n",
      "iter31, loss 1115.0369842586322\n",
      "iter32, loss 1114.9061294614528\n",
      "iter33, loss 1114.707540935653\n",
      "iter34, loss 1114.3691230298862\n",
      "iter35, loss 1113.7447898632452\n",
      "iter36, loss 1112.5844888312313\n",
      "iter37, loss 1110.742330169539\n",
      "iter38, loss 1108.792805587992\n",
      "iter39, loss 1106.7004616520742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter40, loss 1104.1765265998135\n",
      "iter41, loss 1101.4166061552764\n",
      "iter42, loss 1097.9912160243082\n",
      "iter43, loss 1093.8179190531225\n",
      "iter44, loss 1089.2682538589418\n",
      "iter45, loss 1084.3348632386928\n",
      "iter46, loss 1079.201293245826\n",
      "iter47, loss 1074.393004781878\n",
      "iter48, loss 1070.3702678282586\n",
      "iter49, loss 1067.404518265248\n",
      "iter50, loss 1065.5711911009473\n",
      "iter51, loss 1064.6225836435603\n",
      "iter52, loss 1064.180387869546\n",
      "iter53, loss 1063.980390426262\n",
      "iter54, loss 1063.8895857696195\n",
      "iter55, loss 1063.8478680232122\n",
      "iter56, loss 1063.828488426787\n",
      "iter57, loss 1063.8194077825096\n",
      "iter58, loss 1063.8151259129527\n",
      "iter59, loss 1063.8130977360438\n",
      "iter60, loss 1063.8121340148696\n",
      "1063.8121340148696\n",
      "1063.8130977360438\n",
      "loss converged: 0.0009637211742301588\n",
      "-1063.811699852713\n",
      "[0.10727386 0.34221837 0.55050776]\n",
      "[[6.29727181 4.43163691]\n",
      " [0.92130628 0.96906964]\n",
      " [1.22331714 5.83152166]]\n",
      "[[[ 1.7062103   1.3897418 ]\n",
      "  [ 1.3897418   1.3215502 ]]\n",
      "\n",
      " [[ 1.49927144 -0.37267466]\n",
      "  [-0.37267466  1.43398316]]\n",
      "\n",
      " [[ 0.94316582  0.0670025 ]\n",
      "  [ 0.0670025   1.10374237]]]\n",
      "\n",
      " New Run \n",
      "\n",
      "\n",
      "init values\n",
      "[0.33333334 0.33333334 0.33333334]\n",
      "[[0.91677008 0.36808115]\n",
      " [0.21851109 0.32141478]\n",
      " [0.31864345 0.87027821]]\n",
      "[[[0.90059411 0.3562023 ]\n",
      "  [0.3562023  0.24258168]]\n",
      "\n",
      " [[0.02972728 0.16715494]\n",
      "  [0.16715494 1.15974208]]\n",
      "\n",
      " [[0.2577255  0.03850606]\n",
      "  [0.03850606 0.00787851]]]\n",
      "iter0, loss 1217.6606732601028\n",
      "iter1, loss 1167.168936303084\n",
      "iter2, loss 1155.0686413156398\n",
      "iter3, loss 1144.6616832903821\n",
      "iter4, loss 1138.3516478825284\n",
      "iter5, loss 1135.4828475760235\n",
      "iter6, loss 1134.212578067061\n",
      "iter7, loss 1133.6061238243733\n",
      "iter8, loss 1133.260634994341\n",
      "iter9, loss 1132.821071689509\n",
      "iter10, loss 1130.7819218993313\n",
      "iter11, loss 1130.2398381201622\n",
      "iter12, loss 1130.2036440029128\n",
      "iter13, loss 1130.1645933860843\n",
      "iter14, loss 1130.0374302277603\n",
      "iter15, loss 1129.3298102540123\n",
      "iter16, loss 1128.574005913819\n",
      "iter17, loss 1128.5673535862531\n",
      "iter18, loss 1128.5671793845768\n",
      "1128.5671793845768\n",
      "1128.5673535862531\n",
      "loss converged: 0.00017420167637283157\n",
      "-1063.811699852713\n",
      "[0.10727386 0.34221837 0.55050776]\n",
      "[[6.29727181 4.43163691]\n",
      " [0.92130628 0.96906964]\n",
      " [1.22331714 5.83152166]]\n",
      "[[[ 1.7062103   1.3897418 ]\n",
      "  [ 1.3897418   1.3215502 ]]\n",
      "\n",
      " [[ 1.49927144 -0.37267466]\n",
      "  [-0.37267466  1.43398316]]\n",
      "\n",
      " [[ 0.94316582  0.0670025 ]\n",
      "  [ 0.0670025   1.10374237]]]\n",
      "\n",
      " New Run \n",
      "\n",
      "\n",
      "init values\n",
      "[0.33333334 0.33333334 0.33333334]\n",
      "[[0.16979115 0.74724908]\n",
      " [0.13571892 0.1405234 ]\n",
      " [0.26237678 0.8539123 ]]\n",
      "[[[0.58458087 0.77744152]\n",
      "  [0.77744152 1.08930475]]\n",
      "\n",
      " [[1.36821598 1.08808219]\n",
      "  [1.08808219 0.90482464]]\n",
      "\n",
      " [[0.7417872  0.71217803]\n",
      "  [0.71217803 1.10268974]]]\n",
      "iter0, loss 1163.6470675804962\n",
      "iter1, loss 1139.6083326897124\n",
      "iter2, loss 1135.8486795431959\n",
      "iter3, loss 1134.022665130052\n",
      "iter4, loss 1132.6997237197427\n",
      "iter5, loss 1131.6786236529927\n",
      "iter6, loss 1131.0282330335347\n",
      "iter7, loss 1130.649335172583\n",
      "iter8, loss 1130.3696782161387\n",
      "iter9, loss 1130.0993794243814\n",
      "iter10, loss 1129.7914554921235\n",
      "iter11, loss 1129.4153271487428\n",
      "iter12, loss 1128.9778072300646\n",
      "iter13, loss 1128.534342600069\n",
      "iter14, loss 1128.0740291241868\n",
      "iter15, loss 1127.516677659496\n",
      "iter16, loss 1126.8716503427174\n",
      "iter17, loss 1126.2954408715761\n",
      "iter18, loss 1125.9278133826624\n",
      "iter19, loss 1125.7260596168824\n",
      "iter20, loss 1125.5986142155787\n",
      "iter21, loss 1125.500809545814\n",
      "iter22, loss 1125.4160260544877\n",
      "iter23, loss 1125.3351958820701\n",
      "iter24, loss 1125.244620873296\n",
      "iter25, loss 1125.1142690298016\n",
      "iter26, loss 1124.886249365315\n",
      "iter27, loss 1124.4895615227658\n",
      "iter28, loss 1124.0085795963641\n",
      "iter29, loss 1123.6625680182874\n",
      "iter30, loss 1123.4300889654976\n",
      "iter31, loss 1123.2179759478424\n",
      "iter32, loss 1122.9626854244082\n",
      "iter33, loss 1122.5975463308912\n",
      "iter34, loss 1122.0790392611734\n",
      "iter35, loss 1121.4690149014966\n",
      "iter36, loss 1120.861714014114\n",
      "iter37, loss 1120.4680614205067\n",
      "iter38, loss 1120.3450602277364\n",
      "iter39, loss 1120.3036588642576\n",
      "iter40, loss 1120.2791603972025\n",
      "iter41, loss 1120.2610939214362\n",
      "iter42, loss 1120.2478226752748\n",
      "iter43, loss 1120.2387096068685\n",
      "iter44, loss 1120.2329581335068\n",
      "iter45, loss 1120.22962200136\n",
      "iter46, loss 1120.227826993633\n",
      "iter47, loss 1120.2269187513245\n",
      "1120.2269187513245\n",
      "1120.227826993633\n",
      "loss converged: 0.0009082423084691982\n",
      "-1063.811699852713\n",
      "[0.10727386 0.34221837 0.55050776]\n",
      "[[6.29727181 4.43163691]\n",
      " [0.92130628 0.96906964]\n",
      " [1.22331714 5.83152166]]\n",
      "[[[ 1.7062103   1.3897418 ]\n",
      "  [ 1.3897418   1.3215502 ]]\n",
      "\n",
      " [[ 1.49927144 -0.37267466]\n",
      "  [-0.37267466  1.43398316]]\n",
      "\n",
      " [[ 0.94316582  0.0670025 ]\n",
      "  [ 0.0670025   1.10374237]]]\n",
      "Current answer for task Task 4 (EM) is: 1063.811699852713\n"
     ]
    }
   ],
   "source": [
    "best_loss, best_pi, best_mu, best_sigma = train_EM(X, 3)\n",
    "grader.submit_EM(best_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implemented all the steps correctly, your algorithm should converge in about 20 iterations. Let's plot the clusters to see it. We will assign a cluster label as the most probable cluster index. This can be found using matrix $\\gamma$ computed on last E-step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1063.811699852713"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10727386, 0.34221837, 0.55050776])"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.29727181, 4.43163691],\n",
       "       [0.92130628, 0.96906964],\n",
       "       [1.22331714, 5.83152166]])"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gamma = E_step(X, best_pi, best_mu, best_sigma)\n",
    "labels = gamma.argmax(1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, s=30)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authorization & Submission\n",
    "To submit assignment parts to Cousera platform, please, enter your e-mail and your token into variables below. You can generate the token on this programming assignment page. <b>Note:</b> Token expires 30 minutes after generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task Task 4 (EM) is: -1063.811699852713\n"
     ]
    }
   ],
   "source": [
    "grader.submit_EM(best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You want to submit these numbers:\n",
      "Task Task 1 (E-step): 0.5337178741081263\n",
      "Task Task 2 (M-step: mu): 2.899391882050384\n",
      "Task Task 2 (M-step: sigma): 5.9771052168975265\n",
      "Task Task 2 (M-step: pi): 0.5507624459218775\n",
      "Task Task 3 (VLB): -1213.973437451592\n",
      "Task Task 4 (EM): -1063.811699852713\n"
     ]
    }
   ],
   "source": [
    "STUDENT_EMAIL = 'ac00@uw.edu'# EMAIL HERE\n",
    "STUDENT_TOKEN = 'bKNi8FY6PLI3bf4Y'# TOKEN HERE\n",
    "grader.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to submit these answers, run cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "grader.submit(STUDENT_EMAIL, STUDENT_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
